{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in successfully!\n",
      "Finished processing 117 batches\n",
      "Finished processing 118 batches\n",
      "Finished processing 119 batches\n",
      "Finished processing 120 batches\n",
      "Finished processing 121 batches\n",
      "Finished processing 122 batches\n",
      "Finished processing 123 batches\n",
      "Finished processing 124 batches\n",
      "Finished processing 125 batches\n",
      "Finished processing 126 batches\n",
      "Finished processing 127 batches\n",
      "Finished processing 128 batches\n",
      "Finished processing 129 batches\n",
      "Finished processing 130 batches\n",
      "Finished processing 131 batches\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scholarly import scholarly\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from dotenv import load_dotenv\n",
    "from openpyxl import load_workbook\n",
    "import importlib\n",
    "from datetime import datetime\n",
    "\n",
    "# Load env\n",
    "load_dotenv()\n",
    "username = os.getenv(\"HUGGINGFACE_USERNAME\")\n",
    "password = os.getenv(\"HUGGINGFACE_PASSWORD\")\n",
    "\n",
    "# Import files\n",
    "import Python_scripts.login as login\n",
    "import Python_scripts.extract_info as extract_info\n",
    "import Python_scripts.click_commit_dates as click_commit\n",
    "import Python_scripts.click_username as click_username\n",
    "import Python_scripts.click_arxiv_tags as click_arxiv_tags\n",
    "import Python_scripts.space_apps_info as space_apps_info\n",
    "import Python_scripts.get_submission_date as get_submission_date\n",
    "import Python_scripts.click_community as click_community\n",
    "import Python_scripts.check_404_error as check_404_error\n",
    "import Python_scripts.model_page_info as model_page_info\n",
    "importlib.reload(login)\n",
    "importlib.reload(extract_info)\n",
    "importlib.reload(click_commit)\n",
    "importlib.reload(click_username)\n",
    "importlib.reload(click_arxiv_tags)\n",
    "importlib.reload(space_apps_info)\n",
    "importlib.reload(get_submission_date)\n",
    "importlib.reload(click_community)\n",
    "importlib.reload(check_404_error)\n",
    "importlib.reload(model_page_info)\n",
    "\n",
    "# Load links\n",
    "nlp_links = pd.read_excel(\"Outputs/Unedited_sheets/model_info_with_likes&down.xlsx\")\n",
    "nlp_links.reset_index(inplace = True, drop = True)\n",
    "\n",
    "\n",
    "# Determine the starting batch number based on the slice\n",
    "split_number = 500\n",
    "batch_start_number = 1\n",
    "nlp_links = nlp_links[58499:]\n",
    "\n",
    "\n",
    "# Excel file setup\n",
    "output_excel = os.path.join(\"Outputs\", 'model_info_with_likes&down&more_6.xlsx')\n",
    "\n",
    "\n",
    "# Set up Chrome\n",
    "chrome_options = Options()\n",
    "# Display ON/OFF\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "service = Service(executable_path='Dependencies//chromedriver.exe') \n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "login.login_hugging_face(driver, username, password)\n",
    "\n",
    "results = []\n",
    "error_flag = 0\n",
    "\n",
    "\n",
    "# Loop for every link\n",
    "for index, row in nlp_links.iterrows():\n",
    "    language_tag = nlp_links.iloc[0]['Language of the Model']\n",
    "    info_text = nlp_links.iloc[0]['Organization Tags']\n",
    "    downloads_all_time = \"NA\"\n",
    "    has_arxiv = \"NA\"\n",
    "    model_name = \"NA\"\n",
    "    likes_count = \"NA\"\n",
    "    model_card = \"NA\"\n",
    "    model_card_word_count = \"NA\"\n",
    "    space_app_count = \"NA\"\n",
    "    arxiv_links = \"NA\"\n",
    "\n",
    "\n",
    "    link = row['Model Link']\n",
    "    error_flag = check_404_error.check_404_page(driver, link)\n",
    "    if error_flag == 0:\n",
    "        temp_list = model_page_info.extract_info(driver, link)\n",
    "        downloads_all_time = temp_list[0]\n",
    "        has_arxiv = temp_list[1]\n",
    "        model_name = temp_list[2]\n",
    "        likes_count = temp_list[3]\n",
    "        model_card = temp_list[4]\n",
    "        model_card_word_count = temp_list[5]\n",
    "        space_app_count = temp_list[6]\n",
    "        arxiv_links = temp_list[7]\n",
    "        number_of_papers = len(arxiv_links)\n",
    "\n",
    "    results.append({\n",
    "        'Model Link': link,\n",
    "        'Language of the Model' : language_tag,\n",
    "        'Organization Tags' : info_text,\n",
    "        'Downloads All Time': downloads_all_time,\n",
    "        'Likes' : likes_count,\n",
    "        'Number of Space Apps' : space_app_count,\n",
    "        'Valid Link?' : error_flag,\n",
    "        'Model Card': model_card,\n",
    "        'Model Card Length' : model_card_word_count,\n",
    "        'Model Name' : model_name,\n",
    "        'Has Arxiv Tag': has_arxiv,\n",
    "        'Number of Papers' : number_of_papers,\n",
    "        'Links to Paper(s)' : arxiv_links\n",
    "    })\n",
    "    \n",
    "    # Save to Excel every split_number links or when finished\n",
    "    if (index + 1) % split_number == 0 or (index + 1) == len(nlp_links):\n",
    "        output_df = pd.DataFrame(results)\n",
    "        batch_number = batch_start_number + index // split_number\n",
    "        sheet_name = f'Batch_{batch_number}'\n",
    "        print(f\"Finished processing {batch_number} batches\")\n",
    "\n",
    "        if os.path.exists(output_excel):\n",
    "            # Load the workbook\n",
    "            workbook = load_workbook(output_excel)\n",
    "            if sheet_name in workbook.sheetnames:\n",
    "                # If the sheet already exists, remove it\n",
    "                del workbook[sheet_name]\n",
    "                workbook.save(output_excel)\n",
    "            with pd.ExcelWriter(output_excel, mode='a', engine='openpyxl') as writer:\n",
    "                output_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        else:\n",
    "            with pd.ExcelWriter(output_excel, mode='w', engine='openpyxl') as writer:\n",
    "                output_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "        # Clear results list to start next batch\n",
    "        results.clear()\n",
    "\n",
    "# Save any remaining links if the results are not empty after the loop\n",
    "if results:\n",
    "    output_df = pd.DataFrame(results)\n",
    "    batch_number += 1\n",
    "    sheet_name = f'Batch_{batch_number}'\n",
    "    print(f\"Finished processing {batch_number} batches\")\n",
    "\n",
    "    if os.path.exists(output_excel):\n",
    "        workbook = load_workbook(output_excel)\n",
    "        if sheet_name in workbook.sheetnames:\n",
    "            del workbook[sheet_name]\n",
    "            workbook.save(output_excel)\n",
    "        with pd.ExcelWriter(output_excel, mode='a', engine='openpyxl') as writer:\n",
    "            output_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "    else:\n",
    "        with pd.ExcelWriter(output_excel, mode='w', engine='openpyxl') as writer:\n",
    "            output_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "\n",
    "# Close the driver after completion\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct\n",
      "https://huggingface.co/google/gemma-2-2b-it\n",
      "https://huggingface.co/google/gemma-2-2b\n",
      "https://huggingface.co/meta-llama/Meta-Llama-3.1-405B\n",
      "https://huggingface.co/nisten/Biggie-SmoLlm-0.15B-Base\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(i) for i in nlp_links[\"Model Link\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scholarly import scholarly\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from dotenv import load_dotenv\n",
    "from openpyxl import load_workbook\n",
    "import importlib\n",
    "from datetime import datetime\n",
    "\n",
    "# Load env\n",
    "load_dotenv()\n",
    "username = os.getenv(\"HUGGINGFACE_USERNAME\")\n",
    "password = os.getenv(\"HUGGINGFACE_PASSWORD\")\n",
    "\n",
    "# Import files\n",
    "import Python_scripts.login as login\n",
    "import Python_scripts.extract_info as extract_info\n",
    "import Python_scripts.click_commit_dates as click_commit\n",
    "import Python_scripts.click_username as click_username\n",
    "import Python_scripts.click_arxiv_tags as click_arxiv_tags\n",
    "import Python_scripts.space_apps_info as space_apps_info\n",
    "import Python_scripts.get_submission_date as get_submission_date\n",
    "import Python_scripts.click_community as click_community\n",
    "import Python_scripts.check_404_error as check_404_error\n",
    "import Python_scripts.model_page_info as model_page_info\n",
    "importlib.reload(login)\n",
    "importlib.reload(extract_info)\n",
    "importlib.reload(click_commit)\n",
    "importlib.reload(click_username)\n",
    "importlib.reload(click_arxiv_tags)\n",
    "importlib.reload(space_apps_info)\n",
    "importlib.reload(get_submission_date)\n",
    "importlib.reload(click_community)\n",
    "importlib.reload(check_404_error)\n",
    "importlib.reload(model_page_info)\n",
    "\n",
    "# Load links\n",
    "nlp_links = pd.read_excel(\"Outputs/Unedited_sheets/model_info_with_likes&down.xlsx\")\n",
    "nlp_links.reset_index(inplace = True, drop = True)\n",
    "\n",
    "\n",
    "# Determine the starting batch number based on the slice\n",
    "split_number = 500\n",
    "batch_start_number = 1\n",
    "nlp_links = nlp_links[58499:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Link</th>\n",
       "      <th>Language of the Model</th>\n",
       "      <th>Organization Tags</th>\n",
       "      <th>Downloads All Time</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Number of Space Apps</th>\n",
       "      <th>Invalid Link?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58499</th>\n",
       "      <td>https://huggingface.co/bella05/pogny_5_32_0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58500</th>\n",
       "      <td>https://huggingface.co/bwahyuh/digidaw1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58501</th>\n",
       "      <td>https://huggingface.co/ab30atsiwo/finbert-gpt-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58502</th>\n",
       "      <td>https://huggingface.co/ab30atsiwo/finbert-gpt-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58503</th>\n",
       "      <td>https://huggingface.co/movadek/uk-imm-court-ou...</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65151</th>\n",
       "      <td>https://huggingface.co/SaiPavanKumarMeruga/dis...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65152</th>\n",
       "      <td>https://huggingface.co/apriandito/tipe-tweet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65153</th>\n",
       "      <td>https://huggingface.co/Rahul-8853/testtttt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65154</th>\n",
       "      <td>https://huggingface.co/quangtqv/mxbai_rerank_t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65155</th>\n",
       "      <td>https://huggingface.co/AAkay/model11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6657 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Model Link  \\\n",
       "58499     https://huggingface.co/bella05/pogny_5_32_0.01   \n",
       "58500            https://huggingface.co/bwahyuh/digidaw1   \n",
       "58501  https://huggingface.co/ab30atsiwo/finbert-gpt-...   \n",
       "58502  https://huggingface.co/ab30atsiwo/finbert-gpt-...   \n",
       "58503  https://huggingface.co/movadek/uk-imm-court-ou...   \n",
       "...                                                  ...   \n",
       "65151  https://huggingface.co/SaiPavanKumarMeruga/dis...   \n",
       "65152       https://huggingface.co/apriandito/tipe-tweet   \n",
       "65153         https://huggingface.co/Rahul-8853/testtttt   \n",
       "65154  https://huggingface.co/quangtqv/mxbai_rerank_t...   \n",
       "65155               https://huggingface.co/AAkay/model11   \n",
       "\n",
       "      Language of the Model Organization Tags  Downloads All Time  Likes  \\\n",
       "58499                   NaN               NaN                 7.0    0.0   \n",
       "58500                   NaN               NaN                 7.0    0.0   \n",
       "58501                   NaN               NaN                 8.0    0.0   \n",
       "58502                   NaN               NaN                 6.0    0.0   \n",
       "58503               English               NaN                 8.0    0.0   \n",
       "...                     ...               ...                 ...    ...   \n",
       "65151                   NaN               NaN                 4.0    0.0   \n",
       "65152                   NaN               NaN                 4.0    0.0   \n",
       "65153                   NaN               NaN                 0.0    0.0   \n",
       "65154                   NaN               NaN                 5.0    0.0   \n",
       "65155                   NaN               NaN                 NaN    NaN   \n",
       "\n",
       "       Number of Space Apps  Invalid Link?  \n",
       "58499                   0.0              0  \n",
       "58500                   0.0              0  \n",
       "58501                   0.0              0  \n",
       "58502                   0.0              0  \n",
       "58503                   0.0              0  \n",
       "...                     ...            ...  \n",
       "65151                   0.0              0  \n",
       "65152                   0.0              0  \n",
       "65153                   0.0              0  \n",
       "65154                   0.0              0  \n",
       "65155                   NaN              1  \n",
       "\n",
       "[6657 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scholarly import scholarly\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from dotenv import load_dotenv\n",
    "import importlib\n",
    "from datetime import datetime\n",
    "\n",
    "# Load env\n",
    "load_dotenv()\n",
    "username = os.getenv(\"HUGGINGFACE_USERNAME\")\n",
    "password = os.getenv(\"HUGGINGFACE_PASSWORD\")\n",
    "\n",
    "# Import files\n",
    "import Python_scripts.login as login\n",
    "import Python_scripts.extract_info as extract_info\n",
    "import Python_scripts.click_commit_dates as click_commit\n",
    "import Python_scripts.click_username as click_username\n",
    "import Python_scripts.click_arxiv_tags as click_arxiv_tags\n",
    "import Python_scripts.space_apps_info as space_apps_info\n",
    "import Python_scripts.get_submission_date as get_submission_date\n",
    "import Python_scripts.check_404_error as check_404_error\n",
    "importlib.reload(login)\n",
    "importlib.reload(extract_info)\n",
    "importlib.reload(click_commit)\n",
    "importlib.reload(click_username)\n",
    "importlib.reload(click_arxiv_tags)\n",
    "importlib.reload(space_apps_info)\n",
    "importlib.reload(get_submission_date)\n",
    "importlib.reload(check_404_error)\n",
    "\n",
    "# Load links\n",
    "nlp_links = pd.read_csv(\"Outputs/model_links-NLP.csv\")\n",
    "new_link = \"https://huggingface.co/microsoft/Florence-2-large\"\n",
    "nlp_links = pd.concat([pd.DataFrame({\"Model Link\": [new_link]}), nlp_links]).reset_index(drop=True)\n",
    "nlp_links = nlp_links[0:2000]\n",
    "\n",
    "# Set up Chrome\n",
    "chrome_options = Options()\n",
    "# Display ON/OFF\n",
    "# chrome_options.add_argument(\"--headless\")\n",
    "service = Service(executable_path='Dependencies//chromedriver.exe') \n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# login.login_hugging_face(driver, username, password)\n",
    "\n",
    "link = 'https://huggingface.co/aubmindlab/aragpt2-mega-detector-long'\n",
    "\n",
    "error_flag = check_404_error.check_404_page(driver, link)\n",
    "print(error_flag)\n",
    "\n",
    "# Extract info after clicking on the commits link\n",
    "# click_commit_list = click_commit.click_files_and_versions(driver, link)\n",
    "# number_of_commits = click_commit_list[0]\n",
    "# latest_commit_date = click_commit_list[1]\n",
    "# oldest_commit_date = click_commit_list[2]\n",
    "\n",
    "\n",
    "# Extract info after clicking on the ARXIV tags\n",
    "# click_arxiv_tags_list = click_arxiv_tags.get_arxiv_links(driver, link)\n",
    "# arxiv_links = click_arxiv_tags_list[0]\n",
    "# number_of_papers = len(arxiv_links)\n",
    "# submission_dates = click_arxiv_tags_list[1]\n",
    "# submission_dates_dt = [datetime.strptime(date, '%d %b %Y') if date != \"N/A\" else \"N/A\" for date in submission_dates]\n",
    "\n",
    "get_submission_date_list = get_submission_date.get_readme_info(driver, link)\n",
    "arxiv_links_2 = get_submission_date_list[0]\n",
    "published_dates = get_submission_date_list[1]\n",
    "published_dates_dt = [datetime.strptime(date, '%Y-%m-%dT%H:%M:%S') if date != \"N/A\" else \"N/A\" for date in published_dates]\n",
    "\n",
    "# time_differences = [\n",
    "#     \"N/A\" if (pub_date == \"N/A\" or sub_date == \"N/A\") else (pub_date - sub_date).days if pub_date and sub_date else None\n",
    "#     for pub_date, sub_date in zip(published_dates_dt, submission_dates_dt)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2012.15520': '2021-03-11T21:46:39'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Python_scripts.login as login\n",
    "import Python_scripts.extract_info as extract_info\n",
    "import Python_scripts.click_commit_dates as click_commit\n",
    "import Python_scripts.click_username as click_username\n",
    "import Python_scripts.click_arxiv_tags as click_arxiv_tags\n",
    "import Python_scripts.space_apps_info as space_apps_info\n",
    "import Python_scripts.get_submission_date as get_submission_date\n",
    "import Python_scripts.check_404_error as check_404_error\n",
    "importlib.reload(login)\n",
    "importlib.reload(extract_info)\n",
    "importlib.reload(click_commit)\n",
    "importlib.reload(click_username)\n",
    "importlib.reload(click_arxiv_tags)\n",
    "importlib.reload(space_apps_info)\n",
    "importlib.reload(get_submission_date)\n",
    "importlib.reload(check_404_error)\n",
    "\n",
    "chrome_options = Options()\n",
    "# Display ON/OFF\n",
    "# chrome_options.add_argument(\"--headless\")\n",
    "service = Service(executable_path='Dependencies//chromedriver.exe') \n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "commit_url = 'https://huggingface.co/aubmindlab/aragpt2-mega-detector-long/commit/685843487166af81b5cc47f33386f0f107d10d4c'\n",
    "arxiv_tags = ['2012.15520']\n",
    "get_submission_date.check_readme_for_arxiv(driver, commit_url, arxiv_tags)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retinopathy_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
