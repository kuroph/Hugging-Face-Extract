{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 100000 models processed\n",
      "Progress: 200000 models processed\n",
      "Progress: 300000 models processed\n",
      "Progress: 400000 models processed\n",
      "Progress: 500000 models processed\n",
      "Progress: 600000 models processed\n",
      "Progress: 700000 models processed\n",
      "Progress: 800000 models processed\n",
      "Progress: 900000 models processed\n",
      "Progress: 1000000 models processed\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# Load the dependencies from CSV files\n",
    "tag_df = pd.read_csv(\"Dependencies//tag_list.csv\")\n",
    "tag_list = list(tag_df[\"Model Tags\"])\n",
    "org_df = pd.read_csv(\"Dependencies//organizations.csv\")\n",
    "\n",
    "# Base URL for Hugging Face models API\n",
    "BASE_URL = \"https://huggingface.co/api/models\"\n",
    "\n",
    "def get_model_links_and_arxiv(limit):\n",
    "    model_data_list = []\n",
    "    page = 0\n",
    "    page_size = 100\n",
    "    total_fetched = 0\n",
    "\n",
    "    while total_fetched < limit:\n",
    "        url = f\"{BASE_URL}?limit={page_size}&offset={page * page_size}\"\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error: Unable to fetch models (status code: {response.status_code})\")\n",
    "            break\n",
    "        \n",
    "        models_data = response.json()\n",
    "        if not models_data:\n",
    "            # Stop if there are no more models returned\n",
    "            print(f\"No more models to fetch. Total fetched: {total_fetched}\")\n",
    "            break\n",
    "\n",
    "        # Collect model links, arXiv tags, and check for link type\n",
    "        for model in models_data:\n",
    "            if total_fetched < limit:\n",
    "                model_link = f\"https://huggingface.co/{model['modelId']}\"\n",
    "\n",
    "                # Extract the org_id from modelId\n",
    "                org_id = model['modelId'].split('/')[0]\n",
    "\n",
    "                # Check if arXiv tags or related fields exist\n",
    "                arxiv_tags = []\n",
    "                if 'tags' in model:\n",
    "                    arxiv_tags = [tag for tag in model['tags'] if 'arxiv' in tag.lower()]\n",
    "                number_of_papers = len(arxiv_tags)\n",
    "\n",
    "                # Check if any tag from tag_list is present in model's tags\n",
    "                link_type = [tag for tag in model.get('tags', []) if tag in tag_list]\n",
    "                link_type = ', '.join(link_type) if link_type else 'None'\n",
    "\n",
    "                # Look up the organization in org_df based on org_id\n",
    "                if org_id in org_df['Organization ID'].values:\n",
    "                    org_row = org_df[org_df['Organization ID'] == org_id].iloc[0]\n",
    "                    org_name = org_row['Organization Name']\n",
    "                    org_type = org_row['Organization Type']\n",
    "                else:\n",
    "                    org_name = 'NA'\n",
    "                    org_type = 'NA'\n",
    "\n",
    "                model_data_list.append({\n",
    "                    'model_link': model_link,\n",
    "                    'arxiv_tags': arxiv_tags,\n",
    "                    'number_of_papers': number_of_papers,\n",
    "                    'link_type': link_type,\n",
    "                    'org_id': org_id,\n",
    "                    'org_name': org_name,\n",
    "                    'org_type': org_type\n",
    "                })\n",
    "\n",
    "                total_fetched += 1\n",
    "                # Print progress after every 100000 models fetched\n",
    "                if total_fetched % 100000 == 0:\n",
    "                    print(f\"Progress: {total_fetched} models processed\")\n",
    "\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        # Move to the next page\n",
    "        page += 1\n",
    "\n",
    "    return model_data_list\n",
    "\n",
    "# Set the hard limit to 1500000 models\n",
    "limit = 1500000\n",
    "\n",
    "# Fetch model links and their arXiv tags\n",
    "model_data = get_model_links_and_arxiv(limit=limit)\n",
    "\n",
    "# Save the data to a CSV file with the additional columns for organization name and type\n",
    "csv_file = \"model_links_arxiv_link_type_org_info.csv\"\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write the header\n",
    "    writer.writerow(['Model Link', 'ArXiv Tags', 'Number of Papers', 'Link Type', 'Org ID', 'Organization Name', 'Organization Type'])\n",
    "    \n",
    "    # Write the data rows\n",
    "    for data in model_data:\n",
    "        model_link = data['model_link']\n",
    "        arxiv_tags = ', '.join(data['arxiv_tags']) if data['arxiv_tags'] else 'None'\n",
    "        number_of_papers = data['number_of_papers']\n",
    "        link_type = data['link_type']\n",
    "        org_id = data['org_id']\n",
    "        org_name = data['org_name']\n",
    "        org_type = data['org_type']\n",
    "        writer.writerow([model_link, arxiv_tags, number_of_papers, link_type, org_id, org_name, org_type])\n",
    "\n",
    "print(f\"Data saved to {csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retinopathy_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
